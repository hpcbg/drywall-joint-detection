# -*- coding: utf-8 -*-
"""surface-detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DS7xbfMOcG4hd5qwytQzTbtdASre9lil

##Import required libraries
"""

import numpy as np
import pandas as pd
import cv2
import requests
import matplotlib.pyplot as plt
import seaborn as sns # used for plot interactive graph
import seaborn as sns
import plotly.express as px
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from pathlib import Path
from sklearn.model_selection import train_test_split

"""## Load and view the input data"""

# from google.colab import files
# files.upload()

# file_url = 'https://drive.google.com/uc?export=download&id=15gIMFzrmidrlEnK6ZyGniKFlrDze6Pr0&confirm=t' # 200x200 tiles
file_url = 'https://drive.google.com/uc?export=download&id=1LsTAQEZStWlPEYQIacHcqGvI-5T6ANnr&confirm=t' # 100x100 tiles
response = requests.get(file_url, stream=True)
open("archive.zip", "wb").write(response.content)

!unzip -q "archive.zip"

positive_dir = Path('Positive')
negative_dir = Path('Negative')

def generate_df(image_dir, label):
    filepaths = pd.Series(list(image_dir.glob(r'*.png')), name='Filepath').astype(str)
    labels = pd.Series(label, name='Label', index=filepaths.index)
    df = pd.concat([filepaths, labels], axis=1)
    return df

positive_df = generate_df(positive_dir, label="POSITIVE")
negative_df = generate_df(negative_dir, label="NEGATIVE")

df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
df

sns.countplot(df['Label'],label="Count")

"""## Prepare the data"""

train_df, test_df = train_test_split(df,train_size=0.7,shuffle=True,random_state=42)

train_df.shape

test_df.shape

"""**Image Data Generator generates batches of tensor image data with real-time data augmentation.**

**For more insights check the tensorflow official documentation https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator**
"""

train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.2,
    featurewise_center=True,
    featurewise_std_normalization=True,
    zca_whitening=False,
    zca_epsilon=1e-06,
    rotation_range=20,
    width_shift_range=0.0,
    height_shift_range=0.0,
    brightness_range=None,
    shear_range=0.0,
    fill_mode='nearest',
    cval=0.0,
    horizontal_flip=True,
    vertical_flip=True,
    preprocessing_function=None,
    data_format=None,
    interpolation_order=1,
    dtype=None)

test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

"""**flow_from_dataframe checks the path available on the dataframe and then automatically search for the image in train directory. Then it make the desired preprocessing steps available in ImageDataGenerator**

**More insights can be found from this article https://vijayabhaskar96.medium.com/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1**
"""

batch_size = 32
target_size = (100, 100)

train_data = train_gen.flow_from_dataframe(
    train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=target_size,
    color_mode='rgb',
    class_mode='binary',
    batch_size=batch_size,
    shuffle=True,
    seed=42,
    subset='training')

val_data = train_gen.flow_from_dataframe(
    train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=target_size,
    color_mode='rgb',
    class_mode='binary',
    batch_size=batch_size,
    shuffle=True,
    seed=42,
    subset='validation')

test_data = train_gen.flow_from_dataframe(
    test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=target_size,
    color_mode='rgb',
    class_mode='binary',
    batch_size=32,
    shuffle=False,
    seed=42)

test_data.class_indices

image, label = next(iter(train_data))
plt.imshow(image[0])

"""## Create the model"""

# inputs = tf.keras.Input(shape=(120, 120, 3))
# inputs = tf.keras.Input(shape=(200, 200, 3))
inputs = tf.keras.Input(shape=(100, 100, 3))
x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)
x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)
x = tf.keras.layers.GlobalAveragePooling2D()(x)
outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)

model = tf.keras.Model(inputs=inputs, outputs=outputs)

# opt = tf.keras.optimizers.Adam(learning_rate=1e-06)
model.compile(
    optimizer='adam',
#     optimazer=opt,
    loss='binary_crossentropy',
    metrics=['accuracy'])
print(model.summary())

"""## Fitting the model"""

history = model.fit(train_data,validation_data=val_data,epochs=20,
            callbacks=[tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True)])

"""##Save and load the model"""

# model.save('./crack_detection_model')

# file_url = "https://drive.google.com/uc?export=download&id=1iq0p_wQHcpwvENpXZtamao3n-57hTR3i&confirm=t"
# response = requests.get(file_url, stream=True)
# open("model.h5", "wb").write(response.content)

# model = tf.keras.models.load_model("model.h5")

"""## Training history"""

fig = px.line(
    history.history,
    y=['loss', 'val_loss'],
    labels={'index': "Epoch", 'value': "Loss"},
    title="Training and Validation Loss Over Time")
fig.show()

fig = px.line(
    history.history,
    y=['accuracy', 'val_accuracy'],
    labels={'index': "Epoch", 'value': "Accuracy"},
    title="Training and Validation Accuracy Over Time")
fig.show()

def evaluate_model(model, test_data):
    
    results = model.evaluate(test_data, verbose=0)
    loss = results[0]
    acc = results[1]
    
    print("    Test Loss: {:.5f}".format(loss))
    print("Test Accuracy: {:.2f}%".format(acc * 100))

"""## Evaluate the model"""

evaluate_model(model, test_data)

"""**Confusion Matrix**"""

y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(np.int))
cm = confusion_matrix(test_data.labels, y_pred)
clr = classification_report(test_data.labels, y_pred, target_names=["NEGATIVE", "POSITIVE"])
    
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='viridis', cbar=False)
plt.xticks(ticks=np.arange(2) + 0.5, labels=["NEGATIVE", "POSITIVE"])
plt.yticks(ticks=np.arange(2) + 0.5, labels=["NEGATIVE", "POSITIVE"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

print("Classification Report:\n----------------------\n", clr)

"""## Run prediction on a single image"""

img = cv2.imread('Positive/img_12_100_700.png')
img = cv2.resize(img, target_size)
result = model.predict(img[None])
print(result)
print(test_data.next()[0])

def predict_on_crops_serial(input_image, https=False, height=256, width=256, save_crops = False):
    
    if https:
        req = urllib.request.urlopen(input_image)
        arr = np.asarray(bytearray(req.read()), dtype=np.uint8)
        im = cv2.imdecode(arr, -1)
    elif isinstance(input_image, str):
        im = cv2.imread(input_image)
    else:
        im = input_image
        
    try:
        imgheight, imgwidth, channels = im.shape
    except:
        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
        imgheight, imgwidth, channels = im.shape
        
    counter = 1
    output_image = np.zeros_like(im)
    
    
    for i in range(0,imgheight,height):
        for j in range(0,imgwidth,width):
            a = im[i:i+height, j:j+width]
     
#             a = np.expand_dims(a, axis=0)
#             processed_a = test2_datagen.flow(a).next()
             ## discard image cropss that are not full size
#             predicted_class = CLASSES[int(np.argmax(model.predict(processed_a), axis=-1))]

            result = model.predict(a[None], verbose = 0)

        
            if result[0] > 0.5:
                predicted_class = 'Positive'
            else:
                predicted_class = 'Negative'
            
            ## save image
#             file, ext = os.path.splitext(input_image)
#             image_name = file.split('/')[-1]
#             folder_name = 'out_' + image_name
            
            ## Put predicted class on the image
            if predicted_class == 'Positive':
                color = (0,0, 255)
            else:
                color = (0, 255, 0)
#             cv2.putText(a, predicted_class, (50,50), cv2.FONT_HERSHEY_SIMPLEX , 0.7, color, 1, cv2.LINE_AA) 
            b = np.zeros_like(a, dtype=np.uint8)
            b[:] = color
            add_img = cv2.addWeighted(a, 0.9, b, 0.1, 0, dtype=cv2.CV_64F)
            
            ## Save crops
            if save_crops:
                if not os.path.exists(os.path.join('predictions', folder_name)):
                    os.makedirs(os.path.join('predictions', folder_name))
                filename = os.path.join('predictions', folder_name,'img_{}.png'.format(counter))
                cv2.imwrite(filename, add_img)
            output_image[i:i+height, j:j+width,:] = add_img
            counter += 1
    ## Save output image
#     cv2.imwrite(os.path.join('predictions', folder_name+ '.jpg'), output_image)
    
    plt.figure(figsize=(10,10))
    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))

# predict_on_crops_serial('2000x1500_10_resized.jpg', height=100, width=100)

def generate_tiles(input_image, height=256, width=256):
        
    tiles = []
    tiles_position = []
    imgheight, imgwidth, channels = input_image.shape
    for i in range(0, imgheight, height):
        for j in range(0, imgwidth, width):
            tile = input_image[i:i+height, j:j+width]
            tiles.append(tile)
            tiles_position.append((i, j))
    return tiles, tiles_position

# %%time
# image_path = '2000x1500_10_resized.jpg'
# input_image = cv2.imread(image_path) 
# tiles, _ = generate_tiles(input_image, height=100, width=100)

# %%timeit
# results = model.predict(np.array(tiles), verbose = 0)

def draw_tiles_anotation(predictions, input_image, out, tiles, tiles_position, height, width):
    output_image = np.zeros_like(input_image)
    
    for index, tile in enumerate(tiles):     
        if predictions[index] > 0.5:
            color = (0,0, 255)
        else:
            color = (0, 255, 0)
        
        b = np.zeros_like(tile, dtype=np.uint8)
        b[:] = color
        add_img = cv2.addWeighted(tile, 0.9, b, 0.1, 0, dtype=cv2.CV_64F)
        i, j = tiles_position[index]
        output_image[i:i+height, j:j+width,:] = add_img

    if out:
        out.write(output_image)
    else:
        plt.figure(figsize=(10,10))
        plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))

def predict_on_crops(input_image, out, height=256, width=256):
    if isinstance(input_image, str):
        input_image = cv2.imread(input_image)
    tiles, tiles_position = generate_tiles(input_image, height, width)
    predictions = model.predict(np.array(tiles), verbose = 0)
    draw_tiles_anotation(predictions, input_image, out, tiles, tiles_position, height, width)

# Load the image from URL
file_url = "https://drive.google.com/uc?export=download&id=1JveAFQUAzQ7SsKEnTBmBTdXZcxTMQtFw&confirm=t"
response = requests.get(file_url, stream=True)
open("2000x1500_10_resized.jpg", "wb").write(response.content)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# predict_on_crops('2000x1500_10_resized.jpg', out=False, height=100, width=100)

"""## Test on video stream"""

from imutils.video import FileVideoStream

# Load the video file from URL
file_url = "https://drive.google.com/uc?export=download&id=16PefnId4cYOWZuXsP6drEQUpMx_iKtrE&confirm=t"
response = requests.get(file_url, stream=True)
open("drywall2.mp4", "wb").write(response.content)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # cap = cv2.VideoCapture('/data/dataset/videos/drywall2.mp4')
# fvs = FileVideoStream("drywall2.mp4").start()
# out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc(*'MJPG'),30.0, (640,480))
# # while(cap.isOpened()):
# #     ret, frame = cap.read()
# #     if ret==True:
# #         predict_on_crops(frame, out, height=80, width=80)
# #     else:
# #         break
#         
# while fvs.more():
#     frame = fvs.read()
#     if frame is not None:
#         predict_on_crops(frame, out, height=80, width=80)
#     else:
#         break